{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# start the session\n",
    "spark = SparkSession.builder.appName(\"JoinTypes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://github.com/databricks/LearningSparkV2.git\n",
    "tripdelaysFilePath = \"databricks-datasets/learning-spark-v2/flights/departuredelays.csv\"\n",
    "airportsnaFilePath = \"databricks-datasets/learning-spark-v2/flights/airport-codes-na.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|total_rows|\n",
      "+----------+\n",
      "|       526|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportsna = (spark.read\n",
    "                    .format(\"csv\")\n",
    "                    .options(header=\"true\", inferSchema=\"true\", sep=\"\\t\")\n",
    "                    .load(airportsnaFilePath))\n",
    "airportsna.createOrReplaceTempView(\"airports_na\")\n",
    "spark.sql('Select count(*) as total_rows from airports_na').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+----+\n",
      "|      City|State|Country|IATA|\n",
      "+----------+-----+-------+----+\n",
      "|Abbotsford|   BC| Canada| YXX|\n",
      "|  Aberdeen|   SD|    USA| ABR|\n",
      "|   Abilene|   TX|    USA| ABI|\n",
      "|     Akron|   OH|    USA| CAK|\n",
      "|   Alamosa|   CO|    USA| ALS|\n",
      "+----------+-----+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportsna.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|total_rows|\n",
      "+----------+\n",
      "|   1391578|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departureDelays = (spark.read\n",
    "                        .format(\"csv\")\n",
    "                        .options(header=\"true\")\n",
    "                        .load(tripdelaysFilePath))\n",
    "departureDelays.createOrReplaceTempView(\"departureDelays\")\n",
    "spark.sql('Select count(*) as total_rows from departureDelays').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+\n",
      "|    date|delay|distance|origin|destination|\n",
      "+--------+-----+--------+------+-----------+\n",
      "|01011245|    6|     602|   ABE|        ATL|\n",
      "|01020600|   -8|     369|   ABE|        DTW|\n",
      "|01021245|   -2|     602|   ABE|        ATL|\n",
      "|01020605|   -4|     602|   ABE|        ATL|\n",
      "|01031245|   -4|     602|   ABE|        ATL|\n",
      "+--------+-----+--------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departureDelays.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOIN types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+------+-----------+\n",
      "|IATA|    date|delay|origin|destination|\n",
      "+----+--------+-----+------+-----------+\n",
      "| JFK|01300915| 1500|   EGE|        JFK|\n",
      "| JFK|01031442| 1167|   SJU|        JFK|\n",
      "| LGA|01011700| 1017|   MSP|        LGA|\n",
      "| JFK|01291718|  978|   SJU|        JFK|\n",
      "| JFK|02121625|  932|   HNL|        JFK|\n",
      "+----+--------+-----+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, col\n",
    "\n",
    "# get only five flights with the longest delays\n",
    "airportsna.filter(airportsna.State == 'NY').select('IATA') \\\n",
    "    .join(departureDelays.filter(departureDelays.delay > 0).select('date', col('delay').cast('int'), 'origin', 'destination'),\n",
    "          airportsna.IATA == departureDelays.destination,\n",
    "          'inner').sort('delay', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(delay)|\n",
      "+----------+\n",
      "|  970213.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportsna.filter(airportsna.State == 'NY') \\\n",
    "    .join(departureDelays,\n",
    "          airportsna.IATA == departureDelays.destination,\n",
    "          'inner').select(sum('delay')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full/Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+------+-----------+\n",
      "|IATA|    date|delay|origin|destination|\n",
      "+----+--------+-----+------+-----------+\n",
      "|null|01010206|   -4|   SJU|        JFK|\n",
      "| ATL|01010040|   -6|   SLC|        ATL|\n",
      "| ATL|01010030|   -8|   LAS|        ATL|\n",
      "|null|01010500|   -8|   SJU|        JFK|\n",
      "| ATL|01010059|   -9|   DEN|        ATL|\n",
      "| ABY|    null| null|  null|       null|\n",
      "| AGS|    null| null|  null|       null|\n",
      "| AHN|    null| null|  null|       null|\n",
      "| BQK|    null| null|  null|       null|\n",
      "| CSG|    null| null|  null|       null|\n",
      "| MCN|    null| null|  null|       null|\n",
      "| SAV|    null| null|  null|       null|\n",
      "| VLD|    null| null|  null|       null|\n",
      "+----+--------+-----+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportsna.filter(airportsna.State == 'GA').select('IATA') \\\n",
    "    .join(departureDelays.select('date', col('delay').cast('int'), 'origin', 'destination') \\\n",
    "                         .filter((departureDelays.destination.isin(['ATL', 'JFK'])) & (departureDelays.delay <= 0)).sort('date').limit(5),\n",
    "          airportsna.IATA == departureDelays.destination,\n",
    "          'full').sort('delay', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
